{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgL6HsQrp4ff",
    "outputId": "93b1e995-d5fe-4537-86eb-37dc9181977e",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# yolo_v1_full.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torchvision.ops import nms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import VOCDetection\n",
    "\n",
    "\n",
    "VOC_CLASSES = [\n",
    "    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "    'bus', 'car', 'cat', 'chair', 'cow',\n",
    "    'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "]\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(VOC_CLASSES)}\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Configuration\n",
    "# ------------------------------------------------------------------------------\n",
    "class Config:\n",
    "    S = 7               # Grid size\n",
    "    B = 2               # Bounding boxes per cell\n",
    "    C = 20              # Classes (Pascal VOC has 20)\n",
    "    IMAGE_SIZE = 448    # Input 이미지 크기\n",
    "    IMAGE_CH_SIZE = 3\n",
    "    BATCH_SIZE = 16\n",
    "    LR = 1e-4\n",
    "    EPOCHS = 50 #3 # 50\n",
    "    CONF_THRESHOLD = 0.2\n",
    "    NMS_IOU_THRESH = 0.4\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# 논문에 제시된 아키텍처 구성 (YOLOv1)\n",
    "architecture_config = [\n",
    "    (7, 64, 2, 3),       # (kernel_size, filters, stride, padding)\n",
    "    \"M\",                 # maxpool\n",
    "    (3, 192, 1, 1),\n",
    "    \"M\",\n",
    "    (1, 128, 1, 0),\n",
    "    (3, 256, 1, 1),\n",
    "    (1, 256, 1, 0),\n",
    "    (3, 512, 1, 1),\n",
    "    \"M\",\n",
    "    [(1, 256, 1, 0), (3, 512, 1, 1), 4],  # 해당 블록을 4번 반복\n",
    "    (1, 512, 1, 0),\n",
    "    (3, 1024, 1, 1),\n",
    "    \"M\",\n",
    "    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],  # 해당 블록을 2번 반복\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 2, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 1, 1)\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Model Definition (YOLOv1)\n",
    "# ------------------------------------------------------------------------------\n",
    "def create_conv_layers(config, in_channels):\n",
    "    layers = []\n",
    "    for module in config:\n",
    "        if type(module) == tuple:\n",
    "            # 튜플 형태: (kernel_size, filters, stride, padding)\n",
    "            kernel_size, filters, stride, padding = module\n",
    "            layers.append(nn.Conv2d(in_channels, filters, kernel_size, stride, padding))\n",
    "            layers.append(nn.LeakyReLU(0.1))\n",
    "            in_channels = filters\n",
    "        elif module == \"M\":\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        elif type(module) == list:\n",
    "            # 리스트 형태: [ conv1 튜플, conv2 튜플, 반복 횟수 ]\n",
    "            conv1, conv2, num_repeats = module\n",
    "            for _ in range(num_repeats):\n",
    "                # 첫 번째 컨볼루션\n",
    "                k, f, s, p = conv1\n",
    "                layers.append(nn.Conv2d(in_channels, f, k, s, p))\n",
    "                layers.append(nn.LeakyReLU(0.1))\n",
    "                in_channels = f\n",
    "                # 두 번째 컨볼루션\n",
    "                k, f, s, p = conv2\n",
    "                layers.append(nn.Conv2d(in_channels, f, k, s, p))\n",
    "                layers.append(nn.LeakyReLU(0.1))\n",
    "                in_channels = f\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self, in_channels=3, S=7, B=2, C=20): # split_size=7, num_boxes=2, num_classes=20\n",
    "        super(YOLOv1, self).__init__()\n",
    "        self.features = create_conv_layers(architecture_config, in_channels)\n",
    "        # 입력 이미지가 448x448인 경우, 마지막 컨볼루션 feature map은 7x7 (논문 기준)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * 7 * 7, 4096),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),  # 논문에서 사용한 dropout\n",
    "            nn.Linear(4096, S * S * (C + B * 5))\n",
    "        )\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B,3,H,W] → features → [B,1024,S,S]\n",
    "        x = self.features(x)\n",
    "        # classifier → [B, S*S*(5B + C)]\n",
    "        x = self.classifier(x)\n",
    "        # reshape → [B, S, S, 5B + C]\n",
    "        # print('YOLOv1 forward', x.view(-1, self.S, self.S, 5*self.B + self.C).size())\n",
    "        # YOLOv1 forward torch.Size([16, 7, 7, 30])\n",
    "        return x.view(-1, self.S, self.S, 5*self.B + self.C) # 계산 복잡도를 낮추기 위해 (N, S, S, 5*B+C) 형태로 반환한다.\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Loss Function (YOLOv1 original)\n",
    "# ------------------------------------------------------------------------------\n",
    "# 주어진 두 박스의 중심 좌표와 크기를 바탕으로 좌측상단, 우측하단 좌표를 계산하고, 교집합 영역을 통해 IoU를 계산합니다.\n",
    "# IoU 계산 함수 (YOLOv1에서 사용하는 bounding box 형식: [x_center, y_center, width, height])\n",
    "def iou(boxes1, boxes2, eps=1e-6):\n",
    "    \"\"\"\n",
    "    boxes1, boxes2: 텐서, 마지막 차원이 [x_center, y_center, width, height]\n",
    "    \"\"\"\n",
    "    # 좌측 상단, 우측 하단 좌표 계산. (x1,y1,x2,y2)로 변환\n",
    "    box1_x1 = boxes1[:,0] - boxes1[:,2] / 2\n",
    "    box1_y1 = boxes1[:,1] - boxes1[:,3] / 2\n",
    "    box1_x2 = boxes1[:,0] + boxes1[:,2] / 2\n",
    "    box1_y2 = boxes1[:,1] + boxes1[:,3] / 2\n",
    "\n",
    "    box2_x1 = boxes2[:,0] - boxes2[:,2] / 2\n",
    "    box2_y1 = boxes2[:,1] - boxes2[:,3] / 2\n",
    "    box2_x2 = boxes2[:,0] + boxes2[:,2] / 2\n",
    "    box2_y2 = boxes2[:,1] + boxes2[:,3] / 2\n",
    "\n",
    "    # 교집합 영역\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "    inter_w  = (x2 - x1).clamp(min=0)\n",
    "    inter_h  = (y2 - y1).clamp(min=0)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    # 합집합 영역\n",
    "    box1_area = torch.abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = torch.abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "    union = box1_area + box2_area - inter + eps\n",
    "\n",
    "    # IoU: Intersaction over Union\n",
    "    iou_val = inter / union\n",
    "    return iou_val\n",
    "\n",
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, S, B, C, lambda_coord=5, lambda_noobj=0.5):\n",
    "        super().__init__()\n",
    "        self.S, self.B, self.C = S, B, C\n",
    "        self.mse = nn.MSELoss(reduction='sum')\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        pred, target: [N, S, S, 5B+C]\n",
    "        target 포맷: 각 셀 [x, y, w, h, conf, one-hot-class(C)]\n",
    "        \"\"\"\n",
    "        # print('YoloLoss forward', pred.shape) # (16, 7, 7, 30)\n",
    "        B, S, _, _ = pred.shape\n",
    "        coord_loss = 0\n",
    "        obj_loss = 0\n",
    "        noobj_loss = 0\n",
    "        class_loss = 0\n",
    "\n",
    "        # 순회 대신 벡터화 가능하지만, 가독성을 위해 loop 사용\n",
    "        for i in range(S):\n",
    "            for j in range(S):\n",
    "                # target confidence = 1인 셀들\n",
    "                obj_mask = target[:,i,j,4] == 1\n",
    "                noobj_mask = target[:,i,j,4] == 0\n",
    "\n",
    "                # 해당 셀의 예측 박스와 타깃 분리\n",
    "                pred_cell = pred[:, i, j, :5*self.B].view(-1, self.B, 5) # (N, B, 5). 즉, (16, 2, 5)\n",
    "                # print('pred_cell: ', pred_cell.shape)\n",
    "                true_cell = target[:, i, j, :5] # (N, 5)\n",
    "\n",
    "                # ====================\n",
    "                # 0) 책임 박스 좌표\n",
    "                # ====================\n",
    "                if obj_mask.any():\n",
    "                    # 책임 박스 선정: 각 샘플마다 IoU가 최대인 박스 인덱스\n",
    "                    # pred_cell[obj_mask]: [N_obj, B, 5]\n",
    "                    pred_boxes = pred_cell[obj_mask, :, :4] # (N_obj, B, 4)\n",
    "                    # (N_obj, 4) -> (N_obj, 1, 4) -> (N_obj, B, 4): prediction은 박스가 2개이상 일 수 있으니, 계산 용이성을 위해 target도 shape을 똑같이 맞추어 준다.\n",
    "                    true_boxes = true_cell[obj_mask, :4].unsqueeze(1).expand_as(pred_boxes)\n",
    "                    # IoU 계산 후 argmax. 두박스 모두 (N * B, 4)이며 리턴은 (N_obj, B) 이다\n",
    "                    ious = iou(pred_boxes.reshape(-1, 4), true_boxes.reshape(-1, 4)).view(-1, self.B)\n",
    "                    best_idx = torch.argmax(ious, dim=1) # (N_obj,): B개의 박스 중 최고를 선택한다.\n",
    "\n",
    "                    # 책임 박스 좌표\n",
    "                    n_obj = best_idx.size(0) # N_obj\n",
    "                    batch_idx = torch.arange(n_obj, device=pred.device) # [0, ..., N_obj - 1]\n",
    "                    pred_chosen = pred_boxes[batch_idx, best_idx] # (N_obj, 4)\n",
    "                    true_chosen = true_boxes[batch_idx, best_idx] # (N_obj, 4)\n",
    "                    # print('pred_boxes:', pred_boxes.shape)\n",
    "                    # print('ious:', ious)\n",
    "                    # print('best_idx:', best_idx)\n",
    "                    # print('n_obj:', n_obj)\n",
    "                    # print('batch_idx:', batch_idx)\n",
    "\n",
    "                # ====================\n",
    "                # 1) 좌표 손실 (object 셀)\n",
    "                # ====================\n",
    "                if obj_mask.any():\n",
    "                    # 예측에서 B개 박스 중 책임 존재하는 박스 사용\n",
    "                    # 크기 루트 비교\n",
    "                    pred_xy = pred_chosen[:, :2]\n",
    "                    true_xy = true_chosen[:, :2]\n",
    "                    coord_loss += self.mse(pred_xy, true_xy)\n",
    "                    pred_wh = pred_chosen[:, 2:4].clamp(min=1e-6)\n",
    "                    true_wh = true_chosen[:, 2:4]  # target은 음수가 없으므로 clamp 불필요\n",
    "                    coord_loss += self.mse(torch.sqrt(pred_wh), torch.sqrt(true_wh))\n",
    "                    # print('coord_loss: ', coord_loss)\n",
    "\n",
    "                # ====================\n",
    "                # 2) Obejct Confidence 손실\n",
    "                # ====================\n",
    "                # object 셀\n",
    "                if obj_mask.any():\n",
    "                    # Object confidence 손실\n",
    "                    pred_conf = pred_cell[obj_mask, :, 4]      # (N_obj, B)\n",
    "                    # 선택된 conf만 1, 나머지는 noobj 손실에 포함\n",
    "                    chosen_conf = pred_conf[batch_idx, best_idx] # (N_obj,)\n",
    "                    # print('chosen_conf: ', chosen_conf.shape, chosen_conf)\n",
    "                    obj_loss += self.mse(chosen_conf, torch.ones_like(chosen_conf))\n",
    "\n",
    "                    # 나머지 박스는 no-object 손실: 오브젝트가 없다면 해당 loss가 0에 수렴해야 좋은 것임\n",
    "                    noobj_conf_mask = torch.ones_like(pred_conf, dtype=torch.bool) # (N_obj, B)\n",
    "                    noobj_conf_mask[batch_idx, best_idx] = False\n",
    "                    noobj_conf = pred_conf[noobj_conf_mask]\n",
    "                    noobj_loss += self.mse(noobj_conf, torch.zeros_like(noobj_conf))\n",
    "                # no-object 셀 전체 박스\n",
    "                if noobj_mask.any():\n",
    "                    noobj_pred = pred_cell[noobj_mask, :, 4]  # (N_noobj, B)\n",
    "                    noobj_loss += self.mse(noobj_pred,  torch.zeros_like(noobj_pred))\n",
    "                # print('noobj_loss: ', noobj_loss)\n",
    "\n",
    "                # ====================\n",
    "                # 3) Class 손실\n",
    "                # ====================\n",
    "                if obj_mask.any():\n",
    "                    pred_cls = pred[obj_mask, i, j, 5:]\n",
    "                    true_cls = target[obj_mask, i, j, 5:]\n",
    "                    class_loss += self.mse(pred_cls, true_cls)\n",
    "                    # print('class_loss: ', class_loss)\n",
    "\n",
    "        total_loss = (\n",
    "            self.lambda_coord * coord_loss +\n",
    "            obj_loss +\n",
    "            self.lambda_noobj * noobj_loss +\n",
    "            class_loss\n",
    "        )\n",
    "        # print('total_loss: ', total_loss)\n",
    "        return total_loss / B\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Dataset & Dataloader 예시 (Pascal VOC)\n",
    "# ------------------------------------------------------------------------------\n",
    "class VOCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, year='2007', image_set='train', S=7, B=2, C=20, transform=None):\n",
    "        self.dataset = VOCDetection(root, year=year, image_set=image_set, download=True)\n",
    "        self.S, self.B, self.C = S, B, C\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = self.dataset[idx]\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in target['annotation']['object']:\n",
    "            bbox = obj['bndbox']\n",
    "            # 원본 좌표 [1..W/H] → normalized [0..1]\n",
    "            x1 = float(bbox['xmin']) / img.width\n",
    "            y1 = float(bbox['ymin']) / img.height\n",
    "            x2 = float(bbox['xmax']) / img.width\n",
    "            y2 = float(bbox['ymax']) / img.height\n",
    "            boxes.append([x1,y1,x2,y2])\n",
    "            cls_name = obj['name']\n",
    "            labels.append(self.class_to_idx[cls_name])\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # target tensor: [S, S, 5B + C], 초기 0\n",
    "        target_tensor = torch.zeros((self.S, self.S, 5*self.B + self.C))\n",
    "        cell_size = 1.0 / self.S\n",
    "\n",
    "        for box, cls in zip(boxes, labels):\n",
    "            x1,y1,x2,y2 = box\n",
    "            x_center = (x1 + x2) / 2\n",
    "            y_center = (y1 + y2) / 2\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "\n",
    "            i = int(y_center / cell_size)\n",
    "            j = int(x_center / cell_size)\n",
    "            # cell 내 상대 좌표\n",
    "            dx = (x_center - j*cell_size) / cell_size\n",
    "            dy = (y_center - i*cell_size) / cell_size\n",
    "\n",
    "            # 첫 번째 박스 책임 할당\n",
    "            target_tensor[i,j,0:4] = torch.tensor([dx, dy, w, h])\n",
    "            target_tensor[i,j,4] = 1\n",
    "            target_tensor[i,j,5+cls] = 1\n",
    "\n",
    "        return img, target_tensor\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. Post-processing: Decode + NMS\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# 1) Decode 단계: 모델 출력 → 바운딩박스, 점수, 클래스 리스트로 변환\n",
    "def decode_predictions(output, conf_thresh, S, B, C):\n",
    "    \"\"\"\n",
    "    output: [N, S, S, 5B + C]\n",
    "    returns:\n",
    "      batch_boxes   : list of N tensors [M_i, 4]  (x1, y1, x2, y2)\n",
    "      batch_scores  : list of N tensors [M_i]     (score)\n",
    "      batch_classes : list of N tensors [M_i]     (class_idx)\n",
    "    \"\"\"\n",
    "    N = output.size(0)\n",
    "    cell_size = 1.0 / S\n",
    "\n",
    "    batch_boxes, batch_scores, batch_classes = [], [], []\n",
    "    for b in range(N):\n",
    "        preds = output[b]         # [S, S, 5B+C]\n",
    "        boxes, scores, classes = [], [], []\n",
    "\n",
    "        for i in range(S):\n",
    "            for j in range(S):\n",
    "                cell = preds[i, j]             # [5B + C]\n",
    "                class_probs = cell[5*B:]       # [C]\n",
    "                for bi in range(B):\n",
    "                    bx, by, bw, bh, conf = cell[bi*5 : bi*5+5]\n",
    "                    class_scores = conf * class_probs\n",
    "                    max_conf, cls = torch.max(class_scores, dim=0)\n",
    "\n",
    "                    if max_conf > conf_thresh:\n",
    "                        # 격자→절대 좌표 변환\n",
    "                        x_c = (j + bx) * cell_size\n",
    "                        y_c = (i + by) * cell_size\n",
    "                        x1 = x_c - bw/2;  y1 = y_c - bh/2\n",
    "                        x2 = x_c + bw/2;  y2 = y_c + bh/2\n",
    "\n",
    "                        boxes.append([x1, y1, x2, y2])\n",
    "                        scores.append(max_conf)\n",
    "                        classes.append(cls)\n",
    "\n",
    "        if boxes:\n",
    "            batch_boxes.append(torch.tensor(boxes))\n",
    "            batch_scores.append(torch.stack(scores))\n",
    "            batch_classes.append(torch.tensor(classes, dtype=torch.long))\n",
    "        else:\n",
    "            batch_boxes.append(torch.zeros((0,4)))\n",
    "            batch_scores.append(torch.zeros((0,)))\n",
    "            batch_classes.append(torch.zeros((0,), dtype=torch.long))\n",
    "\n",
    "    return batch_boxes, batch_scores, batch_classes\n",
    "\n",
    "# 2) NMS 단계: 클래스별로 Non-Maximum Suppression 적용\n",
    "def apply_nms(batch_boxes, batch_scores, batch_classes, iou_thresh):\n",
    "    \"\"\"\n",
    "    batch_boxes, batch_scores, batch_classes: decode_predictions 반환값\n",
    "    returns: list of N tensors [K_i, 6] → (x1,y1,x2,y2,score,cls)\n",
    "    \"\"\"\n",
    "    batch_dets = []\n",
    "\n",
    "    for boxes, scores, classes in zip(batch_boxes, batch_scores, batch_classes):\n",
    "        if boxes.numel() == 0:\n",
    "            batch_dets.append(torch.zeros((0,6)))\n",
    "            continue\n",
    "\n",
    "        kept = []\n",
    "        for cls_id in classes.unique():\n",
    "            mask = (classes == cls_id)\n",
    "            cls_boxes  = boxes[mask]\n",
    "            cls_scores = scores[mask]\n",
    "            keep_idxs  = nms(cls_boxes, cls_scores, iou_thresh)\n",
    "\n",
    "            if keep_idxs.numel() > 0:\n",
    "                selected = torch.cat([\n",
    "                    cls_boxes[keep_idxs],\n",
    "                    cls_scores[keep_idxs].unsqueeze(1),\n",
    "                    torch.full((keep_idxs.numel(),1), cls_id, dtype=torch.float)\n",
    "                ], dim=1)  # [k,6]\n",
    "                kept.append(selected)\n",
    "\n",
    "        if kept:\n",
    "            batch_dets.append(torch.vstack(kept))\n",
    "        else:\n",
    "            batch_dets.append(torch.zeros((0,6)))\n",
    "\n",
    "    return batch_dets\n",
    "\n",
    "# 3) Wrapper\n",
    "def postprocess(output, conf_thresh, iou_thresh, S, B, C):\n",
    "    boxes, scores, classes = decode_predictions(output, conf_thresh, S, B, C)\n",
    "    return apply_nms(boxes, scores, classes, iou_thresh)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 6. Training & Validation Loop\n",
    "# ------------------------------------------------------------------------------\n",
    "def train_one_epoch(model, loader, loss_fn, opt, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, targets in tqdm(loader, desc='Train batchs'):\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        preds = model(imgs)\n",
    "        # print('train_one_epoch', preds.shape)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in loader:\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            preds = model(imgs)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 7. Main: 학습 및 추론 예시\n",
    "# ------------------------------------------------------------------------------\n",
    "# def main():\n",
    "\n",
    "cfg = Config()\n",
    "# transforms\n",
    "transform = T.Compose([\n",
    "    T.Resize((cfg.IMAGE_SIZE, cfg.IMAGE_SIZE)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "# dataset & loader\n",
    "train_ds = VOCDataset(root='./data', image_set='train', transform=transform, S=cfg.S, B=cfg.B, C=cfg.C)\n",
    "val_ds   = VOCDataset(root='./data', image_set='val',   transform=transform, S=cfg.S, B=cfg.B, C=cfg.C)\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=cfg.BATCH_SIZE)\n",
    "\n",
    "# 모델·손실·최적화기\n",
    "model = YOLOv1(cfg.IMAGE_CH_SIZE, cfg.S, cfg.B, cfg.C).to(cfg.DEVICE)\n",
    "loss_fn = YoloLoss(cfg.S, cfg.B, cfg.C).to(cfg.DEVICE)\n",
    "opt = optim.Adam(model.parameters(), lr=cfg.LR)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(1, cfg.EPOCHS+1):\n",
    "    train_loss = train_one_epoch(model, train_loader, loss_fn, opt, cfg.DEVICE)\n",
    "    val_loss   = validate(model, val_loader, loss_fn, cfg.DEVICE)\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# 추론 예시\n",
    "test_img, _ = val_ds[0]\n",
    "test_pred = model(test_img.unsqueeze(0).to(cfg.DEVICE))\n",
    "detections = postprocess(test_pred, cfg.CONF_THRESHOLD, cfg.NMS_IOU_THRESH, cfg.S, cfg.B, cfg.C)\n",
    "print(\"Sample detections:\", detections[0])\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "'''\n",
    "Train batchs: 100%|██████████| 157/157 [01:48<00:00,  1.44it/s]\n",
    "Epoch 01 | Train Loss: 9.5173 | Val Loss: 7.8427\n",
    "Train batchs: 100%|██████████| 157/157 [01:49<00:00,  1.44it/s]\n",
    "Epoch 02 | Train Loss: 8.2690 | Val Loss: 7.7727\n",
    "Train batchs: 100%|██████████| 157/157 [01:51<00:00,  1.41it/s]\n",
    "Epoch 03 | Train Loss: 298.4498 | Val Loss: 8.7577\n",
    "Train batchs: 100%|██████████| 157/157 [01:51<00:00,  1.41it/s]\n",
    "Epoch 04 | Train Loss: 8.8979 | Val Loss: 7.8043\n",
    "Train batchs: 100%|██████████| 157/157 [01:51<00:00,  1.41it/s]\n",
    "Epoch 05 | Train Loss: 8.4618 | Val Loss: 7.7567\n",
    "Train batchs: 100%|██████████| 157/157 [01:49<00:00,  1.43it/s]\n",
    "Epoch 06 | Train Loss: 8.3562 | Val Loss: 7.7235\n",
    "'''\n",
    "print()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 추론 예시\n",
    "#val_ds   = VOCDataset(root='./data', image_set='val',   transform=transform, S=cfg.S, B=cfg.B, C=cfg.C)\n",
    "#val_loader   = DataLoader(val_ds,   batch_size=cfg.BATCH_SIZE)\n",
    "test_img, _ = val_ds[0]\n",
    "test_pred = model(test_img.unsqueeze(0).to(cfg.DEVICE))\n",
    "detections = postprocess(test_pred, cfg.CONF_THRESHOLD, cfg.NMS_IOU_THRESH, cfg.S, cfg.B, cfg.C)\n",
    "print(\"Sample detections:\", detections[0])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzHZVrC1ssbt",
    "outputId": "19d56e71-0c1c-48cd-8353-cf76052299e5"
   },
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample detections: tensor([], size=(0, 6))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "iXDmSd9adWMH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 삭제된 코드 Snippet (사용하지 마세요)"
   ],
   "metadata": {
    "id": "ah67h_1m507G"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 2. Model Definition (YOLOv1)\n",
    "# ------------------------------------------------------------------------------\n",
    "class YOLOv1_OLD(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=20):\n",
    "        super().__init__()\n",
    "        self.S, self.B, self.C = S, B, C\n",
    "\n",
    "        # 1) Feature Extractor (Darknet-style)\n",
    "        def conv(in_ch, out_ch, k, s=1, p=0):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, k, s, p),\n",
    "                nn.LeakyReLU(0.1, inplace=True)\n",
    "            )\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            conv(3,   64, 7, 2, 3), nn.MaxPool2d(2,2),\n",
    "            conv(64,  192, 3, 1, 1), nn.MaxPool2d(2,2),\n",
    "\n",
    "            conv(192, 128, 1),       conv(128, 256, 3,1,1),\n",
    "            conv(256, 256, 1),       conv(256, 512, 3,1,1),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            *self._make_layers(512, 256, 512, repeats=4),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            *self._make_layers(512, 512, 1024, repeats=2),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            conv(1024, 1024, 3,1,1),\n",
    "            conv(1024, 1024, 3,2,1),\n",
    "            conv(1024, 1024, 3,1,1),\n",
    "            conv(1024, 1024, 3,1,1),\n",
    "        )\n",
    "\n",
    "        # 2) Detection Head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * S * S, 4096),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, S * S * (5*B + C))\n",
    "        )\n",
    "\n",
    "    def _make_layers(self, in_ch, mid_ch, out_ch, repeats):\n",
    "        layers = []\n",
    "        for _ in range(repeats):\n",
    "            layers += [\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_ch, mid_ch, 1),\n",
    "                    nn.LeakyReLU(0.1, inplace=True)\n",
    "                ),\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(mid_ch, out_ch, 3,1,1),\n",
    "                    nn.LeakyReLU(0.1, inplace=True)\n",
    "                )\n",
    "            ]\n",
    "            in_ch = out_ch\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B,3,H,W] → features → [B,1024,S,S]\n",
    "        x = self.features(x)\n",
    "        # classifier → [B, S*S*(5B + C)]\n",
    "        x = self.classifier(x)\n",
    "        # reshape → [B, S, S, 5B + C]\n",
    "        return x.view(-1, self.S, self.S, 5*self.B + self.C)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. Post-processing: Decode + NMS\n",
    "# ------------------------------------------------------------------------------\n",
    "def decode_and_nms(output, conf_thresh, iou_thresh, S, B, C):\n",
    "    \"\"\"\n",
    "    output: [N, S, S, 5B + C]\n",
    "    return: list of detections per image (x1,y1,x2,y2,score,cls)\n",
    "    \"\"\"\n",
    "    batch = []\n",
    "    cell_size = 1.0 / S\n",
    "    for b in range(output.size(0)):\n",
    "        preds = output[b]  # [S,S,5B+C]\n",
    "        boxes_all = []\n",
    "        for i in range(S):\n",
    "            for j in range(S):\n",
    "                cell = preds[i,j]\n",
    "                class_probs = cell[5*B:]\n",
    "                for bi in range(B):\n",
    "                    bx,by,bw,bh,conf = cell[bi*5:bi*5+5]\n",
    "                    score = conf * class_probs\n",
    "                    max_conf, cls = torch.max(score, dim=-1)\n",
    "                    if max_conf > conf_thresh:\n",
    "                        x_center = (j + bx) * cell_size\n",
    "                        y_center = (i + by) * cell_size\n",
    "                        w, h = bw, bh\n",
    "                        x1 = x_center - w/2\n",
    "                        y1 = y_center - h/2\n",
    "                        x2 = x_center + w/2\n",
    "                        y2 = y_center + h/2\n",
    "                        boxes_all.append([x1,y1,x2,y2, max_conf.item(), cls.item()])\n",
    "\n",
    "        if not boxes_all:\n",
    "            batch.append(torch.zeros((0,6)))\n",
    "            continue\n",
    "\n",
    "        boxes = torch.tensor(boxes_all)\n",
    "        keep = []\n",
    "        # 클래스별 NMS\n",
    "        for c in range(C):\n",
    "            mask = boxes[:,5] == c\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            cls_boxes = boxes[mask]\n",
    "            coords = cls_boxes[:,:4]\n",
    "            scores = cls_boxes[:,4]\n",
    "            idxs = nms(coords, scores, iou_thresh)\n",
    "            keep.append(cls_boxes[idxs])\n",
    "        if keep:\n",
    "            batch.append(torch.vstack(keep))\n",
    "        else:\n",
    "            batch.append(torch.zeros((0,6)))\n",
    "    return batch"
   ],
   "metadata": {
    "id": "2cmYF79H5z4w"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "xoidh8_7jK40"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
